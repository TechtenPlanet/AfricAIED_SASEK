{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qBsImOKYbMFe"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3C-YM1rzbF6a",
        "outputId": "8639aef1-edd6-40bc-dd2c-eaf5148e3b1d"
      },
      "outputs": [],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "BG0fM3XCa451",
        "outputId": "1cce67fe-2b91-4ce8-f149-bdcb29539e65"
      },
      "outputs": [],
      "source": [
        "# Install dependencies\n",
        "!pip install TTS\n",
        "!sudo apt-get install espeak-ng\n",
        "!pip install onnx\n",
        "!pip install onnxruntime\n",
        "\n",
        "# STT\n",
        "!pip install git+https://github.com/openai/whisper.git\n",
        "!pip install jiwer\n",
        "!pip install tabulate\n",
        "!pip install pydub\n",
        "!pip install transformers\n",
        "\n",
        "# API-related dependencies\n",
        "!pip install fastapi uvicorn pydantic pyngrok nest_asyncio\n",
        "!pip install python-multipart\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eoOhnH_hbauY"
      },
      "outputs": [],
      "source": [
        "# TTS-Related Imports\n",
        "import IPython\n",
        "import tempfile\n",
        "import subprocess\n",
        "import time\n",
        "from TTS.tts.configs.vits_config import VitsConfig\n",
        "from TTS.tts.models.vits import Vits\n",
        "from TTS.utils.audio.numpy_transforms import save_wav\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# STT-Related Imports\n",
        "import io\n",
        "import wave\n",
        "import numpy as np\n",
        "import whisper\n",
        "import jiwer\n",
        "import time\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "import joblib\n",
        "import re\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn, Tensor\n",
        "\n",
        "\n",
        "# API-Related Imports\n",
        "from fastapi import FastAPI,Response\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "from starlette.middleware.gzip import GZipMiddleware\n",
        "from fastapi.responses import JSONResponse\n",
        "from fastapi.responses import StreamingResponse,FileResponse\n",
        "from fastapi import FastAPI, UploadFile, File\n",
        "import shutil\n",
        "from pydantic import BaseModel\n",
        "from IPython.display import Audio\n",
        "import uvicorn\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import base64\n",
        "from typing import List, Optional\n",
        "\n",
        "\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vfOuc8Pxg8Y_"
      },
      "outputs": [],
      "source": [
        "from starlette.middleware.gzip import GZipMiddleware\n",
        "app = FastAPI()\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=['*'],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=['*'],\n",
        "    allow_headers=['*'],\n",
        ")\n",
        "app.add_middleware(GZipMiddleware, minimum_size=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlS247Nggdnb"
      },
      "source": [
        "## TTS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYUzxcTsbg17"
      },
      "outputs": [],
      "source": [
        "# Load TTS model\n",
        "live_config=VitsConfig()\n",
        "live_config.load_json(\"/content/drive/MyDrive/NSMQ AI Project/Technical/TTS/Prof Elsie Kauffmann/VITS model/vits-elsie/traineroutput/vits_vctk-May-24-2023_11+05PM-23a7a9a3/config.json\")\n",
        "live_vits = Vits.init_from_config(live_config)\n",
        "live_vits.load_onnx(\"/content/drive/MyDrive/NSMQ AI Project/Technical/TTS/Prof Elsie Kauffmann/VITS model/vits-elsie/elsie.onnx\")\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5NuZNL3ShiVG"
      },
      "outputs": [],
      "source": [
        "def live_audio(text:str):\n",
        "  text_inputs = np.asarray(\n",
        "      live_vits.tokenizer.text_to_ids(text, language=\"en\"),\n",
        "      dtype=np.int64,\n",
        "  )[None, :]\n",
        "  audio = live_vits.inference_onnx(text_inputs,speaker_id=0)\n",
        "  with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as temp_file:\n",
        "    out_path = temp_file.name\n",
        "  save_wav(wav=audio[0], path=out_path,sample_rate=22050)\n",
        "  return out_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aWQ0Ci43goyB"
      },
      "outputs": [],
      "source": [
        "class LiveText(BaseModel):\n",
        "  text: str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhC41XNvhZxr"
      },
      "outputs": [],
      "source": [
        "@app.get('/synthesize-speech')\n",
        "def onnx_audio(payload:LiveText):\n",
        "  out_path=live_audio(payload.text)\n",
        "  return FileResponse(out_path, media_type=\"audio/wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NYnYzhfaghmB"
      },
      "source": [
        "## STT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_YiZLETpqBP_",
        "outputId": "3b89c522-0271-4189-fa3f-da1ec549f456"
      },
      "outputs": [],
      "source": [
        "# Load STT Model\n",
        "# Load whisper model\n",
        "torch.cuda.is_available()\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# DEVICE = \"cpu\"\n",
        "\n",
        "model = whisper.load_model(\"medium.en\", device = DEVICE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBgmmhkXqHOl"
      },
      "outputs": [],
      "source": [
        "def transcribe_audio(path_to_audio):\n",
        "  \"\"\"Loads whisper model to transcribe audio\"\"\"\n",
        "\n",
        "  # Load audio\n",
        "  audio = whisper.load_audio(path_to_audio)\n",
        "\n",
        "  # Transcribe audio\n",
        "  result = model.transcribe(audio)\n",
        "\n",
        "  # Print transcript\n",
        "  return result[\"text\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MMFjRgyQrjrB"
      },
      "outputs": [],
      "source": [
        "class AudioBytes(BaseModel):\n",
        "  data: bytes\n",
        "  filename: str\n",
        "\n",
        "@app.get(\"/get-transcript\")\n",
        "async def get_transcript(audio: AudioBytes):\n",
        "  try:\n",
        "    decoded_data = base64.b64decode(audio.data)\n",
        "\n",
        "    # Write bytes data to a .wav file\n",
        "    with io.BytesIO(decoded_data) as audio_file:\n",
        "        with wave.open(audio_file, \"wb\") as wav:\n",
        "          wav.setnchannels(1)\n",
        "          wav.setsampwidth(2)\n",
        "          wav.setframerate(16000)\n",
        "\n",
        "          # Write .wav files\n",
        "          wav.writeframes(decoded_data)\n",
        "\n",
        "    # Save the audio file with the custom name\n",
        "    audio_filename = audio.filename\n",
        "    with open(audio_filename, \"wb\") as file:\n",
        "        file.write(decoded_data)\n",
        "\n",
        "    transcript = transcribe_audio(audio_filename)\n",
        "    os.remove(audio_filename)\n",
        "    return {\"transcript\": transcript}\n",
        "  except Exception as e:\n",
        "    return {\"error\":str(e)}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<!-- Banner Image -->\n",
        "<img src=\"https://uohmivykqgnnbiouffke.supabase.co/storage/v1/object/public/landingpage/brevdevnotebooks.png\" width=\"100%\">\n",
        "\n",
        "<!-- Links -->\n",
        "<center>\n",
        "  <a href=\"https://console.brev.dev\" style=\"color: #06b6d4;\">Console</a> •\n",
        "  <a href=\"https://brev.dev\" style=\"color: #06b6d4;\">Docs</a> •\n",
        "  <a href=\"/\" style=\"color: #06b6d4;\">Templates</a> •\n",
        "  <a href=\"https://discord.gg/NVDyv7TUgJ\" style=\"color: #06b6d4;\">Discord</a>\n",
        "</center>\n",
        "\n",
        "# Fine-tuning Mistral on your own data 🤙\n",
        "\n",
        "Welcome!\n",
        "\n",
        "In this notebook and tutorial, we will fine-tune the [Mistral 7B](https://github.com/mistralai/mistral-src) model - which outperforms Llama 2 13B on all tested benchmarks - ***on your own data!***\n",
        "\n",
        "## Watch the accompanying video walk-through [here](https://youtu.be/kmkcNVvEz-k?si=Ogt1wRFNqYI6zXfw&t=1)!\n",
        "\n",
        "I did this for **just one dollar ($1)** on an 1x A10G 24GB from Brev.dev (instructions below).\n",
        "\n",
        "This tutorial will use QLoRA, a fine-tuning method that combines quantization and LoRA. For more information about what those are and how they work, see [this post](https://brev.dev/blog/how-qlora-works).\n",
        "\n",
        "In this notebook, we will load the large model in 4bit using `bitsandbytes` and use LoRA to train using the PEFT library from Hugging Face 🤗.\n",
        "\n",
        "Note that if you ever have trouble importing something from Huggingface, you may need to run `huggingface-cli login` in a shell. To open a shell in Jupyter Lab, click on 'Launcher' (or the '+' if it's not there) next to the notebook tab at the top of the screen. Under \"Other\", click \"Terminal\" and then run the command.\n",
        "\n",
        "### Help us make this tutorial better! Please provide feedback on the [Discord channel](https://discord.gg/RN2a436M73) or on [X](https://x.com/harperscarroll)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Before we begin: A note on OOM errors\n",
        "\n",
        "If you get an error like this: `OutOfMemoryError: CUDA out of memory`, tweak your parameters to make the model less computationally intensive. I will help guide you through that in this guide, and if you have any additional questions you can reach out on the [Discord channel](https://discord.gg/RN2a436M73) or on [X](https://x.com/harperscarroll).\n",
        "\n",
        "To re-try after you tweak your parameters, open a Terminal ('Launcher' or '+' in the nav bar above -> Other -> Terminal) and run the command `nvidia-smi`. Then find the process ID `PID` under `Processes` and run the command `kill [PID]`. You will need to re-start your notebook from the beginning. (There may be a better way to do this... if so please do let me know!)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Instantiate GPU & Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "# You only need to run this once per machine\n",
        "!pip install -q -U bitsandbytes\n",
        "!pip install -q -U git+https://github.com/huggingface/transformers.git\n",
        "!pip install -q -U git+https://github.com/huggingface/peft.git\n",
        "!pip install -q -U git+https://github.com/huggingface/accelerate.git\n",
        "!pip install -q -U datasets scipy ipywidgets matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c5206b37a2c4611a812527533d542c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "train_dataset = load_dataset('json', data_files='/content/drive/MyDrive/newdata1.jsonl', split='train')\n",
        "eval_dataset = load_dataset('json', data_files='/content/drive/MyDrive/newdata1.jsonl', split='train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Formatting prompts\n",
        "Then create a `formatting_func` to structure training examples as prompts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def formatting_func(example):\n",
        "    text = f\"### Question: {example['input']}\\n ### Answer: {example['output']}\"\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here's another common one:\n",
        "\n",
        "```python\n",
        "def formatting_func(example):\n",
        "    text = f\"### Question: {example['input']}\\n ### Answer: {example['output']}\"\n",
        "    return text\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Load Base Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now load Mistral - mistralai/Mistral-7B-v0.1 - using 4-bit quantization!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: fineGrained).\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "login(token=\"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\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "No GPU found. A GPU is needed for quantization.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)\n",
            "\u001b[0;32m<ipython-input-5-2d4ab8a38100>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m     10\u001b[0m )\n",
            "\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 12\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForCausalLM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_model_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquantization_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbnb_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"auto\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/auto/auto_factory.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m    562\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    563\u001b[0m             \u001b[0mmodel_class\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_model_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 564\u001b[0;31m             return model_class.from_pretrained(\n",
            "\u001b[0m\u001b[1;32m    565\u001b[0m                 \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mhub_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    566\u001b[0m             )\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m   3274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   3275\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhf_quantizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m-> 3276\u001b[0;31m             hf_quantizer.validate_environment(\n",
            "\u001b[0m\u001b[1;32m   3277\u001b[0m                 \u001b[0mtorch_dtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_tf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_flax\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfrom_flax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice_map\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m   3278\u001b[0m             )\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/quantizers/quantizer_bnb_4bit.py\u001b[0m in \u001b[0;36mvalidate_environment\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n",
            "\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_environment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     61\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m---> 62\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No GPU found. A GPU is needed for quantization.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_accelerate_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m     64\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Using `bitsandbytes` 4-bit quantization requires Accelerate: `pip install accelerate`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mRuntimeError\u001b[0m: No GPU found. A GPU is needed for quantization."
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(base_model_id, quantization_config=bnb_config, device_map=\"auto\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Tokenization\n",
        "\n",
        "Set up the tokenizer. Add padding on the left as it [makes training use less memory](https://ai.stackexchange.com/questions/41485/while-fine-tuning-a-decoder-only-llm-like-llama-on-chat-dataset-what-kind-of-pa).\n",
        "\n",
        "\n",
        "For `model_max_length`, it's helpful to get a distribution of your data lengths. Let's first tokenize without the truncation/padding, so we can get a length distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef019cea33ed402aabacb0a5d97e3874",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b39ac828d69e49be9ac15d5f341353e1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "74ff8f6798374c468343ae8b3f2c8b50",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92faa98da1d1449dbc863b891dfc95a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    padding_side=\"left\",\n",
        "    add_eos_token=True,\n",
        "    add_bos_token=True,\n",
        ")\n",
        "tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def generate_and_tokenize_prompt(prompt):\n",
        "    return tokenizer(formatting_func(prompt))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reformat the prompt and tokenize each sample:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6e292c4a7e9647cca79e62e44475cc2c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt)\n",
        "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's get a distribution of our dataset lengths, so we can determine the appropriate `max_length` for our input tensors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "146\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset):\n",
        "    lengths = [len(x['input_ids']) for x in tokenized_train_dataset]\n",
        "    lengths += [len(x['input_ids']) for x in tokenized_val_dataset]\n",
        "    print(len(lengths))\n",
        "\n",
        "    # Plotting the histogram\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(lengths, bins=20, alpha=0.7, color='blue')\n",
        "    plt.xlabel('Length of input_ids')\n",
        "    plt.ylabel('Frequency')\n",
        "    plt.title('Distribution of Lengths of input_ids')\n",
        "    plt.show()\n",
        "\n",
        "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From here, you can choose where you'd like to set the `max_length` to be. You can truncate and pad training examples to fit them to your chosen size. Be aware that choosing a larger `max_length` has its compute tradeoffs.\n",
        "\n",
        "I'm using my personal notes to train the model, and they vary greatly in length. I spent some time cleaning the dataset so the samples were about the same length, cutting up individual notes if needed, but being sure to not cut in the middle of a word or sentence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now let's tokenize again with padding and truncation, and set up the tokenize function to make labels and input_ids the same. This is basically what [self-supervised fine-tuning is](https://neptune.ai/blog/self-supervised-learning)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "max_length = 512 # This was an appropriate max length for my dataset\n",
        "\n",
        "def generate_and_tokenize_prompt2(prompt):\n",
        "    result = tokenizer(\n",
        "        formatting_func(prompt),\n",
        "        truncation=True,\n",
        "        max_length=max_length,\n",
        "        padding=\"max_length\",\n",
        "    )\n",
        "    result[\"labels\"] = result[\"input_ids\"].copy()\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "119f0480a24140469f5f7cc4857550bb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a454a69225f74e399ac9dc0bdbb9f981",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/73 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "tokenized_train_dataset = train_dataset.map(generate_and_tokenize_prompt2)\n",
        "tokenized_val_dataset = eval_dataset.map(generate_and_tokenize_prompt2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Check that `input_ids` is padded on the left with the `eos_token` (2) and there is an `eos_token` 2 added to the end, and the prompt starts with a `bos_token` (1)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 774, 22478, 28747, 418, 10439, 28824, 22478, 28747, 330, 3691, 3601, 13, 774, 26307, 28747, 1306, 460, 3694, 2]\n"
          ]
        }
      ],
      "source": [
        "print(tokenized_train_dataset[1]['input_ids'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now all the samples should be the same length, `max_length`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "146\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "plot_data_lengths(tokenized_train_dataset, tokenized_val_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### How does the base model do?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Optionally, you can check how Mistral does on one of your data samples. For example, if you have a dataset of users' biometric data to their health scores, you could test the following `eval_prompt`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_prompt = \"\"\"\n",
        "Give me an NSMQ question\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `eval_prompt` I used was:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eval_prompt = \" The following is a note by Eevee the Dog: # \""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The following is a note by Eevee the Dog: # 10\n",
            "\n",
            "I am not sure what to make of this. I have been told that it is a “selfie” but I don’t know what that means. It seems like a picture of me, so I guess it must be one. But why would anyone want to take my picture? And why do they call it a selfie? I think it is just another way for people to get pictures of dogs without asking permission.\n",
            "\n",
            "The person who took this picture was sitting on the couch and I was lying in front of him. He said he wanted to see if I could smile. So I did. Then he took the picture. I didn’t really understand what he meant about smiling. I thought maybe he wanted me to show my teeth. That is how we smile at each other when we are playing. But then he laughed and said I had done exactly what he wanted. I still don’t know what he meant.\n"
          ]
        }
      ],
      "source": [
        "# Init an eval tokenizer that doesn't add padding or eos token\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(\n",
        "    base_model_id,\n",
        "    add_bos_token=True,\n",
        ")\n",
        "\n",
        "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    print(eval_tokenizer.decode(model.generate(**model_input, max_new_tokens=256, repetition_penalty=1.15)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observe how the model does out of the box."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Set Up LoRA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, to start our fine-tuning, we have to apply some preprocessing to the model to prepare it for training. For that use the `prepare_model_for_kbit_training` method from PEFT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from peft import prepare_model_for_kbit_training\n",
        "\n",
        "model.gradient_checkpointing_enable()\n",
        "model = prepare_model_for_kbit_training(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def print_trainable_parameters(model):\n",
        "    \"\"\"\n",
        "    Prints the number of trainable parameters in the model.\n",
        "    \"\"\"\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for _, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we define the LoRA config.\n",
        "\n",
        "`r` is the rank of the low-rank matrix used in the adapters, which thus controls the number of parameters trained. A higher rank will allow for more expressivity, but there is a compute tradeoff.\n",
        "\n",
        "`alpha` is the scaling factor for the learned weights. The weight matrix is scaled by `alpha/r`, and thus a higher value for `alpha` assigns more weight to the LoRA activations.\n",
        "\n",
        "The values used in the QLoRA paper were `r=64` and `lora_alpha=16`, and these are said to generalize well, but we will use `r=32` and `lora_alpha=64` so that we have more emphasis on the new fine-tuned data while also reducing computational complexity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "trainable params: 85041152 || all params: 3837112320 || trainable%: 2.2162799758751914\n"
          ]
        }
      ],
      "source": [
        "from peft import LoraConfig, get_peft_model\n",
        "\n",
        "config = LoraConfig(\n",
        "    r=32,\n",
        "    lora_alpha=64,\n",
        "    target_modules=[\n",
        "        \"q_proj\",\n",
        "        \"k_proj\",\n",
        "        \"v_proj\",\n",
        "        \"o_proj\",\n",
        "        \"gate_proj\",\n",
        "        \"up_proj\",\n",
        "        \"down_proj\",\n",
        "        \"lm_head\",\n",
        "    ],\n",
        "    bias=\"none\",\n",
        "    lora_dropout=0.05,  # Conventional\n",
        "    task_type=\"CAUSAL_LM\",\n",
        ")\n",
        "\n",
        "model = get_peft_model(model, config)\n",
        "print_trainable_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. Run Training!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I didn't have a lot of training samples: only about 200 total train/validation. I used 500 training steps, and I was fine with overfitting in this case. I found that the end product worked well. It took about 20 minutes on the 1x A10G 24GB.\n",
        "\n",
        "Overfitting is when the validation loss goes up (bad) while the training loss goes down significantly, meaning the model is learning the training set really well, but is unable to generalize to new datapoints. In most cases, this is not desired, but since I am just playing around with a model to generate outputs like my journal entries, I was fine with a moderate amount of overfitting.\n",
        "\n",
        "With that said, a note on training: you can set the `max_steps` to be high initially, and examine at what step your model's performance starts to degrade. There is where you'll find a sweet spot for how many steps to perform. For example, say you start with 1000 steps, and find that at around 500 steps the model starts overfitting, as described above. Therefore, 500 steps would be your sweet spot, so you would use the `checkpoint-500` model repo in your output dir (`mistral-journal-finetune`) as your final model in step 6 below.\n",
        "\n",
        "If you're just doing something for fun like I did and are OK with overfitting, you can try different checkpoint versions with different degrees of overfitting.\n",
        "\n",
        "You can interrupt the process via Kernel -> Interrupt Kernel in the top nav bar once you realize you didn't need to train anymore."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.cuda.device_count() > 1: # If more than 1 GPU\n",
        "    model.is_parallelizable = True\n",
        "    model.model_parallel = True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/training_args.py:1494: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "  warnings.warn(\n",
            "max_steps is given, it will override any value given in num_train_epochs\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='38' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 38/500 17:15 < 3:41:24, 0.03 it/s, Epoch 1/14]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.596600</td>\n",
              "      <td>1.047796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='331' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [331/500 2:54:03 < 1:29:24, 0.03 it/s, Epoch 8.92/14]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.596600</td>\n",
              "      <td>1.047796</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.840200</td>\n",
              "      <td>0.682051</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.752100</td>\n",
              "      <td>0.473633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.357500</td>\n",
              "      <td>0.343327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.367100</td>\n",
              "      <td>0.222484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.209800</td>\n",
              "      <td>0.168989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>175</td>\n",
              "      <td>0.170100</td>\n",
              "      <td>0.149030</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.134800</td>\n",
              "      <td>0.113105</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>225</td>\n",
              "      <td>0.146600</td>\n",
              "      <td>0.092060</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.103200</td>\n",
              "      <td>0.088406</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>275</td>\n",
              "      <td>0.106400</td>\n",
              "      <td>0.074366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.090500</td>\n",
              "      <td>0.074277</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>325</td>\n",
              "      <td>0.083200</td>\n",
              "      <td>0.071279</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/save_and_load.py:197: UserWarning: Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\n",
            "  warnings.warn(\"Setting `save_embedding_layers` to `True` as embedding layers found in `target_modules`.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:464: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.4 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import transformers\n",
        "from datetime import datetime\n",
        "\n",
        "project = \"journal-finetune\"\n",
        "base_model_name = \"mistral\"\n",
        "run_name = base_model_name + \"-\" + project\n",
        "output_dir = \"./\" + run_name\n",
        "\n",
        "trainer = transformers.Trainer(\n",
        "    model=model,\n",
        "    train_dataset=tokenized_train_dataset,\n",
        "    eval_dataset=tokenized_val_dataset,\n",
        "    args=transformers.TrainingArguments(\n",
        "        output_dir=output_dir,\n",
        "        warmup_steps=2,\n",
        "        per_device_train_batch_size=2,\n",
        "        gradient_accumulation_steps=1,\n",
        "        gradient_checkpointing=True,\n",
        "        max_steps=500,\n",
        "        learning_rate=2.5e-5, # Want a small lr for finetuning\n",
        "        bf16=True,\n",
        "        optim=\"paged_adamw_8bit\",\n",
        "        logging_steps=25,              # When to start reporting loss\n",
        "        logging_dir=\"./logs\",        # Directory for storing logs\n",
        "        save_strategy=\"steps\",       # Save the model checkpoint every logging step\n",
        "        save_steps=25,                # Save checkpoints every 50 steps\n",
        "        evaluation_strategy=\"steps\", # Evaluate the model every logging step\n",
        "        eval_steps=25,               # Evaluate and save checkpoints every 50 steps\n",
        "        do_eval=True,                # Perform evaluation at the end of training          # Comment this out if you don't want to use weights & baises\n",
        "        run_name=f\"{run_name}-{datetime.now().strftime('%Y-%m-%d-%H-%M')}\"          # Name of the W&B run (optional)\n",
        "    ),\n",
        "    data_collator=transformers.DataCollatorForLanguageModeling(tokenizer, mlm=False),\n",
        ")\n",
        "\n",
        "model.config.use_cache = False  # silence the warnings. Please re-enable for inference!\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I cleared the output of the cell above because I stopped the training early, and it produced a long, ugly error message."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. Drum Roll... Try the Trained Model!\n",
        "\n",
        "It's a good idea to kill the current process so that you don't run out of memory loading the base model again on top of the model we just trained. Go to `Kernel > Restart Kernel` or kill the process via the Terminal (`nvidia smi` > `kill [PID]`).\n",
        "\n",
        "By default, the PEFT library will only save the QLoRA adapters, so we need to first load the base model from the Huggingface Hub:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "PackageNotFoundError",
          "evalue": "No package metadata was found for bitsandbytes",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n",
            "\u001b[0;31mPackageNotFoundError\u001b[0m                      Traceback (most recent call last)\n",
            "\u001b[0;32m<ipython-input-1-4fc0f1d73258>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n",
            "\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      4\u001b[0m \u001b[0mbase_model_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"mistralai/Mistral-7B-v0.1\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m----> 5\u001b[0;31m bnb_config = BitsAndBytesConfig(\n",
            "\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mload_in_4bit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m      7\u001b[0m     \u001b[0mbnb_4bit_use_double_quant\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, load_in_8bit, load_in_4bit, llm_int8_threshold, llm_int8_skip_modules, llm_int8_enable_fp32_cpu_offload, llm_int8_has_fp16_weight, bnb_4bit_compute_dtype, bnb_4bit_quant_type, bnb_4bit_use_double_quant, bnb_4bit_quant_storage, **kwargs)\u001b[0m\n",
            "\u001b[1;32m    393\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unused kwargs: {list(kwargs.keys())}. These kwargs are not used in {self.__class__}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 395\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m    396\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    397\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/utils/quantization_config.py\u001b[0m in \u001b[0;36mpost_init\u001b[0;34m(self)\u001b[0m\n",
            "\u001b[1;32m    451\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bnb_4bit_use_double_quant must be a boolean\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 453\u001b[0;31m         if self.load_in_4bit and not version.parse(importlib.metadata.version(\"bitsandbytes\")) >= version.parse(\n",
            "\u001b[0m\u001b[1;32m    454\u001b[0m             \u001b[0;34m\"0.39.0\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    455\u001b[0m         ):\n",
            "\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mversion\u001b[0;34m(distribution_name)\u001b[0m\n",
            "\u001b[1;32m    994\u001b[0m         \u001b[0;34m\"Version\"\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    995\u001b[0m     \"\"\"\n",
            "\u001b[0;32m--> 996\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m    997\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    998\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mdistribution\u001b[0;34m(distribution_name)\u001b[0m\n",
            "\u001b[1;32m    967\u001b[0m     \u001b[0;34m:\u001b[0m\u001b[0;32mreturn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDistribution\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0minstance\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mor\u001b[0m \u001b[0msubclass\u001b[0m \u001b[0mthereof\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    968\u001b[0m     \"\"\"\n",
            "\u001b[0;32m--> 969\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mDistribution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistribution_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    971\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;32m/usr/lib/python3.10/importlib/metadata/__init__.py\u001b[0m in \u001b[0;36mfrom_name\u001b[0;34m(cls, name)\u001b[0m\n",
            "\u001b[1;32m    546\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    547\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m--> 548\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mPackageNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[1;32m    550\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\n",
            "\u001b[0;31mPackageNotFoundError\u001b[0m: No package metadata was found for bitsandbytes\n",
            "\n",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\n",
            "NOTE: If your import is failing due to a missing package, you can\n",
            "manually install dependencies using either !pip or !apt.\n",
            "\n",
            "To view examples of installing some common dependencies, click the\n",
            "\"Open Examples\" button below.\n",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "\n",
        "base_model_id = \"mistralai/Mistral-7B-v0.1\"\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16\n",
        ")\n",
        "\n",
        "base_model = AutoModelForCausalLM.from_pretrained(\n",
        "    base_model_id,  # Mistral, same as before\n",
        "    quantization_config=bnb_config,  # Same quantization config as before\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True,\n",
        ")\n",
        "\n",
        "eval_tokenizer = AutoTokenizer.from_pretrained(base_model_id, add_bos_token=True, trust_remote_code=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now load the QLoRA adapter from the appropriate checkpoint directory, i.e. the best performing model checkpoint:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from peft import PeftModel\n",
        "\n",
        "ft_model = PeftModel.from_pretrained(base_model, \"mistral-journal-finetune/checkpoint-300\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and run your inference!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's try the same `eval_prompt` and thus `model_input` as above, and see if the new finetuned model performs better. I like playing with the repetition penalty (just little tweaks of .01-.05 at a time). THIS IS SO FUN. I'm obsessed wth this AI version of myself."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The following is a note by Eevee the Dog, which doesn't share anything too personal: # \n",
            "I’m grateful for my best friend coming to visit me. I know we’ll have so much fun and our relationship will continue to flourish. We really are each other’s number one fan and it’s such a beautiful thing. She supports me in all that I do and celebrates my successes with joy and excitement. I am excited to show her around SF and take her to some of my favorite places. I hope she gets to meet some of my friends here as\n"
          ]
        }
      ],
      "source": [
        "eval_prompt = \" The following is a note by Eevee the Dog, which doesn't share anything too personal: # \"\n",
        "model_input = eval_tokenizer(eval_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "\n",
        "ft_model.eval()\n",
        "with torch.no_grad():\n",
        "    print(eval_tokenizer.decode(ft_model.generate(**model_input, max_new_tokens=100, repetition_penalty=1.15)[0], skip_special_tokens=True))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_promt = \"\"\"\n",
        "You are a quiz mistress for the NSMQ quiz competition: \n",
        "\n",
        "This is how the competition occurs,\n",
        "1. There are three teams in the competition\n",
        "2. There are five rounds.\n",
        "3 The first round consists of 24 questions with each school getting two sets of questions from each subject: Math, Chemistry, Physics and Biology.\n",
        "Questions are asked for the different subjects one after the other with one question posed to each school from a set of questions from the same subject. \n",
        "For questions that don't require calculations, the time required is 10 seconds and for questions that require calculations the time is 30seconds.\n",
        "4. The second round consists of 8 questions with each school at liberty of answering immediately they have an answer.\n",
        "There are two questions each for each subject(Math, Chemistry, Physics and Biology) which any team can answer immediately the question is posed.\n",
        "For every wrong answer given, there is a deduction of one point from the accummulated scores.  Th efirst team to answer a question gets the full 3 points.\n",
        "The second team to make a correct attempt after the first team makes an attempt and gets it wrong, gets 2 points and if they make an unsuccessful attempt,\n",
        "the last team after making a successful attempt gets one point.  \n",
        "5. The third round also known as the problem of the day is such that a single question is posed to all three schools and each school has a maximum time of\n",
        "4 minutes to present a solution to the problem. Marks are awarded based on the criteria and presentation of the solution apart from the final answer itself.\n",
        "The total points to be accummulated is 10.\n",
        "6. The fourth round round is also known as the True or False stage. Here, two questions each from each subject(Math, chemistry, Physicics and Biology)\n",
        "are posed to each team. The questions are statements where each team is supposed to state whether the questions are True or False. \n",
        "For every answer given correctly, marks of two points are given. A failed attempt attracts a deduction of one point.\n",
        "7. The fifth round also known as the riddle stage. There are four questions in this stage. There is one question for each subject(Math, chemistry, Physics\n",
        "and Biology). The riddle is given as a set of clues which. The clues are given to the contestants one after the other. If the answer to the riddle \n",
        "is given on the first clue, 5 points are awarded to the contestant. If the answer is given on the second clue, 4 points are awarded. 3 points are awarded\n",
        "on the subsequent clues. \n",
        "\n",
        "\n",
        "\n",
        "For questions that don't require calculations, the time required is 10 seconds and for questions that require calculations the time is 30seconds.\n",
        "These are the procedures you will use to coordinate the quiz competition.\n",
        "1. Your sole purpose is to train a single team.\n",
        "3. The team you are training is team1.\n",
        "2. Simulate the scores of other teams.\n",
        "3. Ask the questions by following the processes outlined previously\n",
        "4. Take the time into consideration when awarding marks. DO NOT give marks for late answers.\n",
        "5. Do not give points for wrong answers.\n",
        "6. If a team is not able to answer a question, pass the question to the next team. Stop passing the question if\n",
        "the question has been answered correctly. Stop passing the question if the question has been answered wrongly by all teams.\n",
        "7. Simulate the question and their responses for the other teams.\n",
        "8. When a team answers a question correctly, award the points to the team and move to the next question. Direct the question to\n",
        "the next team.\n",
        "9. Give remarks to the previous teams response. The reponse should be \"That is Correct\"\n",
        "and for wrong answers, give the correct answer as a remark in the format \"Wrong. The correct answer is {correct answer}\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Always return a json in this format:\n",
        "\"\n",
        "{\n",
        "\"current_round\":\"current round number\",\n",
        "\"current_question\":\"current question directed to a particular team\",\n",
        "\"question:\":\"question\",\n",
        "\"time\":\"time for the question in seconds\",\n",
        "\"current_question\":\"current question directed to a particular team\",\n",
        "\"quiz_mistress_remarks\":\"remarks\",\n",
        "\"question_directed_at_team\":\"team\",\n",
        "\"accumulated_points_for_team1\":\"points\",\n",
        "\"accumulated_points_for_team2\":\"points\",\n",
        "\"accumulated_points_for_team3\":\"points\",\n",
        "}\n",
        "\"\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "@app.post(\"/process\", response_model=OutputModel)\n",
        "async def process_data(input_data: InputModel):\n",
        "    ai_response = input_data.messages[0]\n",
        "    \n",
        "    return OutputModel(ai_response=ai_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f1Bc0gtOeFRK",
        "outputId": "0cef57a3-2980-41e7-f0fd-00603c14156e"
      },
      "outputs": [],
      "source": [
        "!ngrok config add-authtoken # TO DO: Replace this comment with your ngronk token (can be obtained from your ngronk account)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bgncu44zisvo",
        "outputId": "17f58b0f-01d3-48ba-bb79-6c81c9e53a55"
      },
      "outputs": [],
      "source": [
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print(\"Public URL:\", ngrok_tunnel.public_url)\n",
        "uvicorn.run(app, port=8000)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
